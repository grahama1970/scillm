{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f17bb7c",
   "metadata": {},
   "source": [
    "# Router.parallel_acompletions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4160dda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, asyncio\n",
    "from litellm import Router\n",
    "router = Router(default_litellm_params={\n",
    "  'api_base': os.environ['CHUTES_API_BASE'],\n",
    "  'api_key': None,\n",
    "  'custom_llm_provider': 'openai_like',\n",
    "  'extra_headers': {'x-api-key': os.environ['CHUTES_API_KEY'], 'Authorization': os.environ['CHUTES_API_KEY']},\n",
    "})\n",
    "prompts = ['Say OK-A','Say OK-B','Say OK-C']\n",
    "reqs = [{'model': os.environ['CHUTES_MODEL'], 'messages':[{'role':'user','content':p}], 'kwargs': {'max_tokens': 8, 'temperature': 0}} for p in prompts]\n",
    "async def run():\n",
    "  out = await router.parallel_acompletions(requests=reqs, concurrency=3)\n",
    "  print([o.get('choices',[{}])[0].get('message',{}).get('content','') for o in out])\n",
    "asyncio.run(run())"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}