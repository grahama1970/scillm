{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "4fd1551f",
      "metadata": {},
      "source": [
        "### Runtime setup\n",
        "The following envs enable stable retries and quiet streaming.\n",
        "\n",
        "- `SCILLM_DISABLE_AIOHTTP=1` (httpx-only async stability)\n",
        "- `SCILLM_FORCE_HTTPX_STREAM=1`\n",
        "- `LITELLM_MAX_RETRIES=3`, `LITELLM_RETRY_AFTER=1`, `LITELLM_TIMEOUT=45`\n",
        "- Requires `tenacity` installed for backoff."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f88260cd",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ.setdefault('SCILLM_DISABLE_AIOHTTP','1')\n",
        "os.environ.setdefault('SCILLM_FORCE_HTTPX_STREAM','1')\n",
        "os.environ.setdefault('LITELLM_MAX_RETRIES','3')\n",
        "os.environ.setdefault('LITELLM_RETRY_AFTER','1')\n",
        "os.environ.setdefault('LITELLM_TIMEOUT','45')\n",
        "try:\n",
        "    import tenacity  # noqa: F401\n",
        "    print('tenacity: ok')\n",
        "except Exception:\n",
        "    print('tenacity missing — run: pip install tenacity')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "861aedc0",
      "metadata": {},
      "source": [
        "# Router.parallel_acompletions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba65d162",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os, asyncio\n",
        "import nest_asyncio; nest_asyncio.apply()\n",
        "from scillm import Router\n",
        "router = Router(default_litellm_params={\n",
        "  'api_base': os.environ['CHUTES_API_BASE'],\n",
        "  'api_key': os.environ['CHUTES_API_KEY'],\n",
        "  'custom_llm_provider': 'openai_like',\n",
        "})\n",
        "prompts = ['OK-A','OK-B','OK-C']\n",
        "reqs = [{\n",
        "  'model': os.environ['CHUTES_MODEL'],\n",
        "  'messages': [{'role':'user','content': p}],\n",
        "  'kwargs': {'max_tokens': 8, 'temperature': 0, 'timeout': 20}\n",
        "} for p in prompts]\n",
        "async def run():\n",
        "  outs = await router.parallel_acompletions(requests=reqs, concurrency=2)\n",
        "  print([ (o.get('choices',[{}])[0].get('message',{}).get('content','') or '').strip() for o in outs ])\n",
        "loop = asyncio.get_event_loop()\n",
        "loop.run_until_complete(run())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0712db0e",
      "metadata": {},
      "source": [
        "### Router + Fallbacks (Text & VLM) — Recommended\n",
        "Batch/parallel paths work with Router too. Define routers per kind and call them in your batch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e5a6d75",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from litellm import Router\n",
        "router_vlm = Router(model_list=[\n",
        "  {\"model_name\": \"chutes/vlm\",\n",
        "   \"litellm_params\": {\"custom_llm_provider\": \"openai_like\",\n",
        "     \"model\": os.environ.get('CHUTES_VLM_MODEL',''),\n",
        "     \"api_base\": os.environ['CHUTES_API_BASE'],\n",
        "     \"api_key\": os.environ['CHUTES_API_KEY'],\n",
        "     \"order\": 1}},\n",
        "  {\"model_name\": \"chutes/vlm\",\n",
        "   \"litellm_params\": {\"custom_llm_provider\": \"openai_like\",\n",
        "     \"model\": os.environ.get('CHUTES_VLM_MODEL_ALT1',''),\n",
        "     \"api_base\": os.environ['CHUTES_API_BASE'],\n",
        "     \"api_key\": os.environ['CHUTES_API_KEY'],\n",
        "     \"order\": 2}},\n",
        "])\n",
        "out = router_vlm.completion(\n",
        "  model='chutes/vlm',\n",
        "  messages=[{\"role\":\"user\",\"content\":[{\"type\":\"text\",\"text\":'Return only {\\\"ok\\\": true} as JSON.'}]}],\n",
        "  response_format={\"type\":\"json_object\"},\n",
        ")\n",
        "print(out.choices[0].message.get('content',''))\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
