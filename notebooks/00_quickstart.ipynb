{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fbaa884",
   "metadata": {},
   "source": [
    "> Tip: For single‑model, dataset‑safe retries (keeps calling until capacity clears), see the companion notebook: `15_tenacious_single_model.ipynb`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 00 Quickstart — SciLLM + Chutes (JSON)\n",
    "\n",
    "Minimal, first‑success notebook. Uses Auto Router to discover a healthy candidate and returns strict JSON. Set env in your shell before running:\n",
    "\n",
    "- `SCILLM_CHUTES_CANONICALIZE_OPENAI_AUTH=1`\n",
    "- `LITELLM_MAX_RETRIES=3 LITELLM_RETRY_AFTER=2`\n",
    "- `SCILLM_COOLDOWN_429_S=120 SCILLM_RATE_LIMIT_QPS=2`\n",
    "- optional: `SCILLM_DISABLE_AIOHTTP=1 LITELLM_TIMEOUT=45`\n",
    "\n",
    "Requires: `CHUTES_API_BASE`, `CHUTES_API_KEY`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from scillm.extras import auto_router_from_env\n",
    "base = os.getenv('CHUTES_API_BASE'); key = os.getenv('CHUTES_API_KEY')\n",
    "if not (base and key):\n",
    "    print('Missing CHUTES_API_BASE/CHUTES_API_KEY — set them in your shell and rerun.')\n",
    "else:\n",
    "    router = auto_router_from_env(kind='text', require_json=True)\n",
    "    out = router.completion(\n",
    "        model='chutes/text',\n",
    "        messages=[{'role':'user','content':'Return only {\\\"ok\\\": true} as JSON.'}],\n",
    "        response_format={'type':'json_object'},\n",
    "    )\n",
    "    print(out.choices[0].message.get('content',''))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6af9a0",
   "metadata": {},
   "source": [
    "### Troubleshooting — curl header check (DevOps)\n",
    "Validates your tenant accepts either Bearer or x-api-key on /v1/models. Prints HTTP status lines and a short ID slice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010c99d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, subprocess\n",
    "base=os.getenv('CHUTES_API_BASE'); key=os.getenv('CHUTES_API_KEY')\n",
    "if not (base and key):\n",
    "    print('Missing CHUTES_API_BASE/CHUTES_API_KEY — set and rerun.')\n",
    "else:\n",
    "    print('Bearer:')\n",
    "    cmd=\"curl -sS -D - -o - -H 'authorization: Bearer %s' '%s/models'\" % (key, base)\n",
    "    r=subprocess.run(cmd, shell=True, capture_output=True, text=True)\n",
    "    head=r.stderr.splitlines()[:1] if r.stderr else []\n",
    "    print(head[0] if head else 'HTTP/2 ?')\n",
    "    try:\n",
    "        data=json.loads(r.stdout)\n",
    "        ids=[d.get('id','') for d in data.get('data',[])][:8]\n",
    "        print('ids:', ids)\n",
    "    except Exception:\n",
    "        print('body bytes:', len(r.stdout))\n",
    "    print('\n",
    "'+'x-api-key:')\n",
    "    cmd=\"curl -sS -D - -o - -H 'x-api-key: %s' '%s/models'\" % (key, base)\n",
    "    r=subprocess.run(cmd, shell=True, capture_output=True, text=True)\n",
    "    head=r.stderr.splitlines()[:1] if r.stderr else []\n",
    "    print(head[0] if head else 'HTTP/2 ?')\n",
    "    try:\n",
    "        data=json.loads(r.stdout)\n",
    "        ids=[d.get('id','') for d in data.get('data',[])][:8]\n",
    "        print('ids:', ids)\n",
    "    except Exception:\n",
    "        print('body bytes:', len(r.stdout))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab6be90",
   "metadata": {},
   "source": [
    "### Standard Calls Overview\n",
    "\n",
    "This notebook shows multiple standard ways to make calls:\n",
    "- Text JSON (direct OpenAI‑compatible)\n",
    "- Inline multimodal (image_url)\n",
    "- Small batch (sequential, safe)\n",
    "- Router one‑liner (already above)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c6a260",
   "metadata": {},
   "source": [
    "### Text JSON (direct OpenAI‑compatible)\n",
    "\n",
    "Minimal strict‑JSON call against your OpenAI‑compatible base. Uses response_format to enforce JSON.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66141d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from scillm import completion\n",
    "base=os.getenv('CHUTES_API_BASE'); key=os.getenv('CHUTES_API_KEY'); text_model=os.getenv('CHUTES_TEXT_MODEL')\n",
    "if not (base and key and text_model):\n",
    "    print('Missing CHUTES_API_BASE/CHUTES_API_KEY/CHUTES_TEXT_MODEL — set and rerun.')\n",
    "else:\n",
    "    resp = completion(\n",
    "      model=text_model, api_base=base, api_key=key, custom_llm_provider='openai_like',\n",
    "      messages=[{'role':'user','content':'Return only {\\\"ok\\\": true} as JSON.'}],\n",
    "      response_format={'type':'json_object'}, temperature=0, max_tokens=16,\n",
    "    )\n",
    "    print(resp.choices[0].message.get('content',''))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3678989a",
   "metadata": {},
   "source": [
    "### Inline Multimodal (image_url)\n",
    "\n",
    "Send an OpenAI‑style content list with an `image_url` part. This works for VLM models on compatible gateways.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da86304",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from scillm import completion\n",
    "base=os.getenv('CHUTES_API_BASE'); key=os.getenv('CHUTES_API_KEY'); vlm_model=os.getenv('CHUTES_VLM_MODEL','')\n",
    "if not (base and key and vlm_model):\n",
    "    print('Missing CHUTES_* VLM vars — set CHUTES_VLM_MODEL and rerun.')\n",
    "else:\n",
    "    msg=[{'type':'text','text':'Return only {\\\"ok\\\": true} as JSON.'},\n",
    "         {'type':'image_url','image_url':{'url':'https://upload.wikimedia.org/wikipedia/commons/thumb/3/3f/Fronalpstock_big.jpg/640px-Fronalpstock_big.jpg'}}]\n",
    "    resp = completion(\n",
    "      model=vlm_model, api_base=base, api_key=key, custom_llm_provider='openai_like',\n",
    "      messages=[{'role':'user','content': msg}],\n",
    "      response_format={'type':'json_object'}, temperature=0, max_tokens=32,\n",
    "    )\n",
    "    print(resp.choices[0].message.get('content',''))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a241989f",
   "metadata": {},
   "source": [
    "### Small Batch (sequential, safe)\n",
    "\n",
    "Demonstrates a tiny sequential batch for strict JSON prompts. Use Router for production batch with fallbacks and backoff.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025e6e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from scillm import completion\n",
    "base=os.getenv('CHUTES_API_BASE'); key=os.getenv('CHUTES_API_KEY'); text_model=os.getenv('CHUTES_TEXT_MODEL')\n",
    "prompts=[\n",
    "  'Return only {\\\"ok\\\": true} as JSON.',\n",
    "  'Return only {\\\"ok\\\": \\\"batch\\\"} as JSON.'\n",
    "]\n",
    "outs=[]\n",
    "if not (base and key and text_model):\n",
    "    print('Missing CHUTES envs — set and rerun.')\n",
    "else:\n",
    "    for p in prompts:\n",
    "        r = completion(\n",
    "          model=text_model, api_base=base, api_key=key, custom_llm_provider='openai_like',\n",
    "          messages=[{'role':'user','content': p}], response_format={'type':'json_object'},\n",
    "          temperature=0, max_tokens=16,\n",
    "        )\n",
    "        outs.append(r.choices[0].message.get('content',''))\n",
    "    print(outs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc010a2",
   "metadata": {},
   "source": [
    "### Codex‑Agent (OpenAI‑compatible) — JSON call\n",
    "\n",
    "Most common SciLLM path for reasoning tasks. Points at a Codex agent base (OpenAI‑compatible), returns strict JSON.\n",
    "Set in your shell: `CODEX_AGENT_API_BASE`, `CODEX_AGENT_API_KEY`. Optional: `CODEX_AGENT_MODEL` (default 'gpt-5' alias).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39bbb1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from scillm import completion\n",
    "cbase=os.getenv('CODEX_AGENT_API_BASE'); ckey=os.getenv('CODEX_AGENT_API_KEY'); cmodel=os.getenv('CODEX_AGENT_MODEL','gpt-5')\n",
    "if not (cbase and ckey):\n",
    "    print('Missing CODEX_AGENT_API_BASE/CODEX_AGENT_API_KEY — set and rerun.')\n",
    "else:\n",
    "    out = completion(\n",
    "      model=cmodel, api_base=cbase, api_key=ckey, custom_llm_provider='codex-agent',\n",
    "      messages=[{'role':'user','content':'Return only {\\\"ok\\\": true} as JSON.'}],\n",
    "      response_format={'type':'json_object'}, reasoning_effort='high', temperature=0, max_tokens=64,\n",
    "    )\n",
    "    print(out.choices[0].message.get('content',''))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
