{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run metadata (generated 2025-10-27 20:39:43Z)\n\n- SCILLM_FORCE_HTTPX_STREAM=\n- LITELLM_MAX_RETRIES=\n- LITELLM_RETRY_AFTER=\n- LITELLM_TIMEOUT=\n- SCILLM_ALLOW_TOOLS_SMOKE=\n- SCILLM_ALLOW_STREAM_SMOKE="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run metadata (generated 2025-10-27 19:49:26Z)\n\n- SCILLM_FORCE_HTTPX_STREAM=\n- LITELLM_MAX_RETRIES=\n- LITELLM_RETRY_AFTER=\n- LITELLM_TIMEOUT=\n- SCILLM_ALLOW_TOOLS_SMOKE=\n- SCILLM_ALLOW_STREAM_SMOKE="
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ffe189d",
      "metadata": {},
      "source": [
        "### Runtime setup\n",
        "The following envs enable stable retries and quiet streaming.\n",
        "\n",
        "- `SCILLM_FORCE_HTTPX_STREAM=1`\n",
        "- `LITELLM_MAX_RETRIES=3`, `LITELLM_RETRY_AFTER=1`, `LITELLM_TIMEOUT=45`\n",
        "- Requires `tenacity` installed for backoff."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "51cd62d4",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-10-27T19:44:18.583226Z",
          "iopub.status.busy": "2025-10-27T19:44:18.583118Z",
          "iopub.status.idle": "2025-10-27T19:44:18.590543Z",
          "shell.execute_reply": "2025-10-27T19:44:18.589939Z"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tenacity: ok\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.environ.setdefault('SCILLM_FORCE_HTTPX_STREAM','1')\n",
        "os.environ.setdefault('LITELLM_MAX_RETRIES','3')\n",
        "os.environ.setdefault('LITELLM_RETRY_AFTER','1')\n",
        "os.environ.setdefault('LITELLM_TIMEOUT','45')\n",
        "try:\n",
        "    import tenacity  # noqa: F401\n",
        "    print('tenacity: ok')\n",
        "except Exception:\n",
        "    print('tenacity missing \u2014 run: pip install tenacity')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7a97be7d",
      "metadata": {},
      "source": [
        "# Advanced \u2014 Tools only (smoke)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "451a96dd",
      "metadata": {},
      "source": [
        "### Why/When/Gotchas/Troubleshooting\n",
        "- Why: call function tools (OpenAI-format) with SciLLM.\n",
        "- When: structured actions, deterministic JSON I/O.\n",
        "- Gotchas: rate limits (429) \u2014 set max_retries/retry_after/timeout; annotate tool schema clearly.\n",
        "- Troubleshooting: set SCILLM_ALLOW_TOOLS_SMOKE=1 to run the cell; inspect printed tool_calls."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6773e20d",
      "metadata": {},
      "source": [
        "## Curl sanity (documentation)\n",
        "\n",
        "        ```bash\n",
        "        curl -X POST \\\n",
        "          $CHUTES_API_BASE/chat/completions \\\n",
        "          -H \"Authorization: Bearer $CHUTES_API_KEY\" \\\n",
        "          -H \"Content-Type: application/json\" \\\n",
        "          -d '{\n",
        "            \"model\": \"$CHUTES_VLM_MODEL\",\n",
        "            \"messages\": [{\"role\":\"user\",\"content\":\"Tell me a 250 word story.\"}],\n",
        "            \"stream\": true,\n",
        "            \"max_tokens\": 256,\n",
        "            \"temperature\": 0.7\n",
        "          }'\n",
        "        ```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "3388bf87",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-10-27T19:44:18.591812Z",
          "iopub.status.busy": "2025-10-27T19:44:18.591706Z",
          "iopub.status.idle": "2025-10-27T19:44:19.905364Z",
          "shell.execute_reply": "2025-10-27T19:44:19.904810Z"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Skipping tools smoke \u2014 set SCILLM_ALLOW_TOOLS_SMOKE=1 to run\n"
          ]
        }
      ],
      "source": [
        "import os, json\n",
        "from scillm import completion\n",
        "tools=[{'type':'function','function':{'name':'ack','description':'Acknowledge','parameters':{'type':'object','properties':{'ok':{'type':'boolean'}},'required':['ok']}}}]\n",
        "if os.getenv('SCILLM_ALLOW_TOOLS_SMOKE','0').lower() not in {'1','true','yes'}:\n",
        "  print('Skipping tools smoke \u2014 set SCILLM_ALLOW_TOOLS_SMOKE=1 to run')\n",
        "else:\n",
        "  resp = completion(\n",
        "  model=os.environ.get('CHUTES_TOOLS_MODEL', os.environ.get('CHUTES_MODEL_ADVANCED', os.environ['CHUTES_MODEL'])),\n",
        "  api_base=os.environ['CHUTES_API_BASE'],\n",
        "  api_key=None,\n",
        "  custom_llm_provider='openai_like',\n",
        "  extra_headers={'Authorization': f\"Bearer {os.environ['CHUTES_API_KEY']}\"},\n",
        "  messages=[{'role':'user','content':'Call ack with ok=true'}],\n",
        "  tools=tools,\n",
        "  temperature=0,\n",
        "  max_tokens=32,\n",
        "  max_retries=3, retry_after=1, timeout=30,\n",
        ")\n",
        "  print(getattr(resp.choices[0], 'tool_calls', None))"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}